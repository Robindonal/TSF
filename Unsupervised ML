# ROBIN DONAL
## TSF DATA SCIENCE INTERN
## TASK 2
### PREDICTION USING UNSUPERVISED ML

# Importing libraraies
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Reading the dataset
df=pd.read_csv(r"Downloads\Iris.csv")
df
# Summarising the dataset
# Check the null values
df.isnull().any()
df.shape
#getting information of dataset
df.info()
# EDA
# let's plot pair plot to visualise the attributes all at once
sns.pairplot(data=df, hue = 'Species')
# correlation matrix
sns.heatmap(df.corr())
# K means clustering
x = df.iloc[:, [0,1,2,3]].values
#Finding the optimum number of clusters for k-means classification

from sklearn.cluster import KMeans

wcss = []

for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
    kmeans.fit(x)
    wcss.append (kmeans.inertia_)

#Plotting the results onto a Line graph, allowing us to observe 'The elbow'
plt.plot (range (1, 11), wcss)
plt.title("The elbow method")
plt.xlabel("Number of clusters")
plt.ylabel('WCSS') #within cluster sum of squares
plt.show()
#Applying kmeans to the dataset/creating the means classifier
kmeans = KMeans (n_clusters = 3, init = "k-means++", max_iter = 300, n_init = 10, random_state = 0) 
y_kmeans = kmeans.fit_predict(x)
#visualising the clusters
plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c='red', label = "Iris setosa") 
plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c= 'blue', label = "Iris-versicolour") 
plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c='green', label="Iris-virginica")

#plotting the centrolds of the clusters 
plt.scatter (kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], s= 100, c="yellow", label='Centroids')
plt.legend()
